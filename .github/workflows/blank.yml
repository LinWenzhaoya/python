import pandas as pd
import jieba
import pyLDAvis
from joblib import parallel_backend
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.svm import SVC
from gensim import corpora, models
import pyLDAvis
import pyLDAvis.gensim_models as gensimvis
import matplotlib.pyplot as plt
 

# 假设我们已经使用八爪鱼采集器获得了评论数据，并将其保存在CSV文件中
data = pd.read_excel(r"D:\daima\pinlun.xlsx")
data = data.dropna(subset=['标签'])

# 添加一个函数，用于加载停用词列表
def load_stopwords(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        stopwords = [line.strip() for line in f.readlines()]
    return set(stopwords)

# 加载停用词
stopwords = load_stopwords(r"D:\daima\tingyong.txt")

# 更新分词函数，去除停用词
def cut_and_remove_stopwords(text):
    words = jieba.cut(text)
    return ' '.join([word for word in words if word not in stopwords and not word.isspace() and len(word) > 1])

# 对评论内容进行分词并去除停用词
data['cut_comment'] = data['评价内容'].apply(cut_and_remove_stopwords)




# 特征提取
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(data['cut_comment'])
y = data['标签']  # 假设已经进行了人工标注
# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)

# 使用支持向量机进行分类
clf = SVC(probability=True)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

# 评估指标
print("Accuracy: ", accuracy_score(y_test, y_pred))
print("Precision: ", precision_score(y_test, y_pred))
print("Recall: ", recall_score(y_test, y_pred))
print("F1 Score: ", f1_score(y_test, y_pred))
print("ROC AUC: ", roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))

# LDA主题模型分析
# 将文本转换为词袋表示
data['cut_comment'] = data['cut_comment'].apply(lambda x: x.split())
dictionary = corpora.Dictionary(data['cut_comment'])
corpus = [dictionary.doc2bow(text) for text in data['cut_comment']]

# 训练LDA模型
lda = models.LdaModel(corpus, num_topics=4, id2word=dictionary, passes=20)

# 可视化主题模型
vis_data = gensimvis.prepare(lda, corpus, dictionary, n_jobs=1, mds='mmds')
pyLDAvis.display(vis_data)
pyLDAvis.save_html(vis_data, r"D:\daima\pinlun.html")


# 输出每个主题的前10个关键词及其权重
for i, topic in enumerate(lda.show_topics(num_words=10, formatted=False)):
    print(f"Topic {i + 1}:")
    for word, weight in topic[1]:
        print(f"{word}: {weight}")
    print()
